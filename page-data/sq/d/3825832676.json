{"data":{"projects":{"edges":[{"node":{"frontmatter":{"title":"La qualite de code sur les projects Scala/Spark en appliquant TDD et SonarQube","tech":["TDD","SonarQube","Unittest","ScalaTest","Coverage"],"github":"","external":"/pensieve/green-coding/"},"html":""}},{"node":{"frontmatter":{"title":"Spark - Dynamique partition overwrite data","tech":["spark","partition","scala"],"github":null,"external":"/pensieve/spark/dynamique-overwrite"},"html":""}},{"node":{"frontmatter":{"title":"Continuous Integration & Continuous Delivery pour data pipeline en Scala/Spark","tech":["Maven","Ansible","Github","Jenkins"],"github":"","external":"/pensieve/cicd/"},"html":""}},{"node":{"frontmatter":{"title":"Continuous Integration & Continuous Delivery pour data pipeline en Scala/Spark","tech":["Maven","Ansible","Github","Jenkins"],"github":"","external":"/pensieve/cicd/"},"html":""}},{"node":{"frontmatter":{"title":"Build a Data Product","tech":["Data lakehouse","Data product","Starburst","Materialized view"],"github":null,"external":"/pensieve/materialized-view"},"html":"<p>The Data products allows you to publish, find, and manage curated data assets in your organization. Use data products as a semantic layer to abstract the technical complexity of your underlying data sources.</p>"}},{"node":{"frontmatter":{"title":"API Informatica","tech":["Python","Celery","Redis","Ansible","Kubernetes"],"github":"","external":"/pensieve/api-informatica"},"html":"<p>Un CRUD pour Ã©viter les actions manuelles de l'administrateur d'Informatica</p>"}}]}}}